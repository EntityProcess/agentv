import { afterEach, describe, expect, it, vi } from "vitest";

import type { Evaluator } from "../../src/evaluation/evaluators.js";
import { runEvaluation } from "../../src/evaluation/orchestrator.js";
import type { ResolvedTarget } from "../../src/evaluation/providers/targets.js";
import type { Provider, ProviderRequest, ProviderResponse } from "../../src/evaluation/providers/types.js";
import type { EvalCase } from "../../src/evaluation/types.js";
import * as yamlParser from "../../src/evaluation/yaml-parser.js";

class StubBatchProvider implements Provider {
  readonly id = "stub";
  readonly kind = "mock";
  readonly targetName: string;
  readonly supportsBatch = true;
  invokeCalls = 0;
  invokeBatchCalls = 0;

  constructor(targetName: string, private readonly batchShouldThrow = false) {
    this.targetName = targetName;
  }

  async invoke(request: ProviderRequest): Promise<ProviderResponse> {
    this.invokeCalls += 1;
    return { text: `single-${request.evalCaseId ?? "unknown"}` };
  }

  async invokeBatch(requests: readonly ProviderRequest[]): Promise<readonly ProviderResponse[]> {
    this.invokeBatchCalls += 1;
    if (this.batchShouldThrow) {
      throw new Error("batch failure");
    }
    return requests.map((request) => ({ text: `batch-${request.evalCaseId ?? "unknown"}` }));
  }
}

const stubEvaluator: Evaluator = {
  kind: "llm_judge",
  async evaluate(context) {
    return {
      score: 1,
      hits: [`hit-${context.candidate}`],
      misses: [],
      expectedAspectCount: 0,
    };
  },
};

const target: ResolvedTarget = {
  kind: "mock",
  name: "stub-target",
  providerBatching: true,
  config: {},
};

const evalCases: EvalCase[] = [
  {
    id: "one",
    dataset: "batch-dataset",
    question: "t1",
    input_segments: [],
    reference_answer: "",
    guideline_paths: [],
    file_paths: [],
    code_snippets: [],
    expected_outcome: "",
    evaluator: "llm_judge",
  },
  {
    id: "two",
    dataset: "batch-dataset",
    question: "t2",
    input_segments: [],
    reference_answer: "",
    guideline_paths: [],
    file_paths: [],
    code_snippets: [],
    expected_outcome: "",
    evaluator: "llm_judge",
  },
];

afterEach(() => {
  vi.restoreAllMocks();
});

function mockParsers(): void {
  vi.spyOn(yamlParser, "loadEvalCases").mockResolvedValue(evalCases);
  vi.spyOn(yamlParser, "buildPromptInputs").mockImplementation(async (testCase) => ({
    question: `req-${testCase.id}`,
    guidelines: "",
    systemMessage: undefined,
    chatPrompt: undefined,
  }));
}

describe("runEvaluation provider batching", () => {
  it("uses provider-managed batching when enabled", async () => {
    mockParsers();
    const provider = new StubBatchProvider(target.name);

    const results = await runEvaluation({
      testFilePath: "dummy.yaml",
      repoRoot: ".",
      target,
      env: {},
      evaluators: { llm_judge: stubEvaluator },
      providerFactory: () => provider,
      maxRetries: 0,
    });

    expect(provider.invokeBatchCalls).toBe(1);
    expect(provider.invokeCalls).toBe(0);
    expect(results.map((r) => r.candidate_answer)).toEqual(["batch-one", "batch-two"]);
  });

  it("falls back to per-case dispatch when batch fails", async () => {
    mockParsers();
    const provider = new StubBatchProvider(target.name, true);

    const results = await runEvaluation({
      testFilePath: "dummy.yaml",
      repoRoot: ".",
      target,
      env: {},
      evaluators: { llm_judge: stubEvaluator },
      providerFactory: () => provider,
      maxRetries: 0,
    });

    expect(provider.invokeBatchCalls).toBe(1);
    expect(provider.invokeCalls).toBe(evalCases.length);
    expect(results.map((r) => r.candidate_answer)).toEqual(["single-one", "single-two"]);
  });
});
