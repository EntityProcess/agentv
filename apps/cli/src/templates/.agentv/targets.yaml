# A list of all supported evaluation targets for the project.
# Each target defines a provider and its specific configuration.
# Actual values for paths/keys are stored in the local .env file.

targets:
  - name: default
    provider: azure
    endpoint: ${{ AZURE_OPENAI_ENDPOINT }}
    api_key: ${{ AZURE_OPENAI_API_KEY }}
    model: ${{ AZURE_DEPLOYMENT_NAME }}
    # version: ${{ AZURE_OPENAI_API_VERSION }}  # Optional: uncomment to override default (2024-12-01-preview)

  - name: vscode
    provider: vscode
    judge_target: azure_base

  - name: codex
    provider: codex
    judge_target: azure_base
    # Uses the Codex CLI (defaults to `codex` on PATH)
    # executable: ${{ CODEX_CLI_PATH }}        # Optional: override executable path
    # args:                             # Optional additional CLI arguments
    #   - --profile
    #   - ${{ CODEX_PROFILE }}
    #   - --model
    #   - ${{ CODEX_MODEL }}
    #   - --ask-for-approval
    #   - ${{ CODEX_APPROVAL_PRESET }}
    timeout_seconds: 180
    cwd: ${{ CODEX_WORKSPACE_DIR }}            # Where scratch workspaces are created
    log_dir: ${{ CODEX_LOG_DIR }}              # Optional: where Codex CLI stream logs are stored (defaults to ./.agentv/logs/codex)
    log_format: json                    # Optional: 'summary' (default) or 'json' for raw event logs

  # Claude - Anthropic's Claude Agent SDK
  - name: claude
    provider: claude
    judge_target: azure_base
    # Uses the @anthropic-ai/claude-agent-sdk
    # model: claude-sonnet-4-20250514          # Optional: override model
    timeout_seconds: 180
    # cwd: ${{ CLAUDE_WORKSPACE_DIR }}         # Optional: working directory (defaults to process.cwd())
    # max_turns: 50                            # Optional: max conversation turns
    # max_budget_usd: 5.0                      # Optional: max cost budget in USD
    # log_dir: ${{ CLAUDE_LOG_DIR }}           # Optional: where stream logs are stored (defaults to ./.agentv/logs/claude)
    log_format: json                           # Optional: 'summary' (default) or 'json' for raw event logs
    # system_prompt: optional override (default instructs agent to include code in response)

  - name: vscode_projectx
    provider: vscode
    workspace_template: ${{ PROJECTX_WORKSPACE_PATH }}
    provider_batching: false
    judge_target: azure_base

  - name: vscode_insiders_projectx
    provider: vscode-insiders
    workspace_template: ${{ PROJECTX_WORKSPACE_PATH }}
    provider_batching: false
    judge_target: azure_base

  - name: azure_base
    provider: azure
    endpoint: ${{ AZURE_OPENAI_ENDPOINT }}
    api_key: ${{ AZURE_OPENAI_API_KEY }}
    model: ${{ AZURE_DEPLOYMENT_NAME }}
    version: ${{ AZURE_OPENAI_API_VERSION }}

  - name: gemini_base
    provider: gemini
    api_key: ${{ GOOGLE_GENERATIVE_AI_API_KEY }}
    model: ${{ GEMINI_MODEL_NAME }}

  - name: local_cli
    provider: cli
    judge_target: azure_base
    # Passes the fully rendered prompt and any attached files to a local Python script
    # NOTE: Do not add quotes around {PROMPT} or {FILES} - they are already shell-escaped
    command_template: uv run ./mock_cli.py --prompt {PROMPT} {FILES} --output {OUTPUT_FILE}
    # Format for each file in {FILES}. {path} and {basename} are automatically shell-escaped, so no quotes needed
    files_format: --file {path}
    # Optional working directory resolved from .env
    cwd: ${{ CLI_EVALS_DIR }}
    timeout_seconds: 30
    healthcheck:
      type: command
      command_template: uv run ./mock_cli.py --healthcheck
