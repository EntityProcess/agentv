{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "AgentV Eval Schema",
  "description": "Schema for YAML evaluation files with conversation flows, multiple evaluators, and execution configuration",
  "type": "object",
  "properties": {
    "description": {
      "type": "string",
      "description": "Description of what this eval suite covers"
    },
    "target": {
      "type": "string",
      "description": "(Deprecated: use execution.target instead) Default target configuration name. Can be overridden per test."
    },
    "execution": {
      "type": "object",
      "description": "Default execution configuration for all tests (can be overridden per test)",
      "properties": {
        "target": {
          "type": "string",
          "description": "Default target configuration name (e.g., default, azure_base, vscode_projectx). Can be overridden per test."
        },
        "evaluators": {
          "type": "array",
          "description": "Default evaluators appended to every test's evaluators (unless skip_defaults is set per test)",
          "items": {
            "type": "object",
            "properties": {
              "name": {
                "type": "string",
                "description": "Evaluator name/identifier"
              },
              "type": {
                "type": "string",
                "enum": [
                  "code",
                  "llm_judge",
                  "composite",
                  "tool_trajectory",
                  "field_accuracy",
                  "latency",
                  "cost",
                  "token_usage"
                ],
                "description": "Evaluator type: 'code' for scripts/regex/keywords, 'llm_judge' for LLM-based evaluation"
              },
              "script": {
                "type": "string",
                "description": "Path to evaluator script (for type: code)"
              },
              "prompt": {
                "type": "string",
                "description": "Path to judge prompt file (for type: llm_judge)"
              }
            },
            "required": ["name", "type"],
            "additionalProperties": true
          }
        }
      },
      "additionalProperties": true
    },
    "tests": {
      "type": "array",
      "description": "Array of evaluation tests",
      "minItems": 1,
      "items": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "description": "Unique identifier for the test"
          },
          "conversation_id": {
            "type": "string",
            "description": "Optional conversation identifier for threading multiple tests together"
          },
          "criteria": {
            "type": "string",
            "description": "Description of what the AI should accomplish in this eval"
          },
          "note": {
            "type": "string",
            "description": "Optional note or additional context for the test. Use this to document test-specific considerations, known limitations, or rationale for expected behavior."
          },
          "input": {
            "description": "Input messages for the conversation. String expands to single user message, array of messages passes through.",
            "oneOf": [
              {
                "type": "string",
                "description": "Shorthand: single user message content"
              },
              {
                "type": "array",
                "description": "Array of messages",
                "minItems": 1,
                "items": {
                  "type": "object",
                  "properties": {
                    "role": {
                      "type": "string",
                      "enum": ["system", "user", "assistant", "tool"],
                      "description": "Message role"
                    },
                    "content": {
                      "oneOf": [
                        {
                          "type": "string",
                          "description": "Simple text content"
                        },
                        {
                          "type": "array",
                          "description": "Mixed content items (text and file references)",
                          "items": {
                            "type": "object",
                            "properties": {
                              "type": {
                                "type": "string",
                                "enum": ["text", "file"],
                                "description": "Content type: 'text' for inline content, 'file' for file references"
                              },
                              "value": {
                                "type": "string",
                                "description": "Text content or file path. Relative paths (e.g., ../prompts/file.md) are resolved from eval file directory. Absolute paths (e.g., /docs/examples/prompts/file.md) are resolved from repo root."
                              }
                            },
                            "required": ["type", "value"],
                            "additionalProperties": false
                          }
                        }
                      ]
                    }
                  },
                  "required": ["role", "content"],
                  "additionalProperties": false
                }
              }
            ]
          },
          "expected_output": {
            "description": "Expected response messages. String expands to single assistant message, object wraps as assistant message content. The content of the last resolved entry becomes the template variable 'reference_answer'.",
            "oneOf": [
              {
                "type": "string",
                "description": "Shorthand: single assistant message content"
              },
              {
                "type": "object",
                "description": "Shorthand: structured content wraps as assistant message"
              },
              {
                "type": "array",
                "description": "Array of messages",
                "items": {
                  "type": "object",
                  "properties": {
                    "role": {
                      "type": "string",
                      "enum": ["system", "user", "assistant", "tool"],
                      "description": "Message role"
                    },
                    "content": {
                      "oneOf": [
                        {
                          "type": "string",
                          "description": "Simple text content"
                        },
                        {
                          "type": "object",
                          "description": "Structured content object"
                        },
                        {
                          "type": "array",
                          "description": "Mixed content items",
                          "items": {
                            "type": "object",
                            "properties": {
                              "type": {
                                "type": "string",
                                "enum": ["text", "file"]
                              },
                              "value": {
                                "type": "string"
                              }
                            },
                            "required": ["type", "value"],
                            "additionalProperties": false
                          }
                        }
                      ]
                    }
                  },
                  "required": ["role", "content"],
                  "additionalProperties": false
                }
              }
            ]
          },
          "execution": {
            "type": "object",
            "description": "Per-case execution configuration",
            "properties": {
              "target": {
                "type": "string",
                "description": "Override target for this specific test"
              },
              "skip_defaults": {
                "type": "boolean",
                "description": "When true, root-level execution.evaluators are not appended to this test's evaluators"
              },
              "evaluators": {
                "type": "array",
                "description": "Per-test evaluators (root-level evaluators are appended unless skip_defaults is true)",
                "items": {
                  "type": "object",
                  "properties": {
                    "name": {
                      "type": "string",
                      "description": "Evaluator name/identifier"
                    },
                    "type": {
                      "type": "string",
                      "enum": ["code", "llm_judge"],
                      "description": "Evaluator type: 'code' for scripts/regex/keywords, 'llm_judge' for LLM-based evaluation"
                    },
                    "script": {
                      "type": "string",
                      "description": "Path to evaluator script (for type: code)"
                    },
                    "prompt": {
                      "type": "string",
                      "description": "Path to judge prompt file (for type: llm_judge)"
                    }
                  },
                  "required": ["name", "type"],
                  "additionalProperties": true
                }
              }
            },
            "additionalProperties": true
          }
        },
        "required": ["id", "criteria"],
        "anyOf": [{ "required": ["input"] }],
        "additionalProperties": true
      }
    }
  },
  "required": ["tests"],
  "additionalProperties": false
}
