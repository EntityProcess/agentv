# AgentV Rubric Evaluator Example
# Demonstrates the rubric-based evaluation feature

description: Example showing rubric evaluator with inline rubrics and expected_outcome

execution:
  target: default

evalcases:
  # ==========================================
  # Example 1: Simple inline rubrics
  # Demonstrates: inline rubrics as strings, expected_outcome field
  # ==========================================
  - id: code-explanation-simple

    expected_outcome: |-
      Provide a clear explanation of how quicksort works, including time complexity

    input_messages:
      - role: user
        content: Explain how the quicksort algorithm works

    expected_messages:
      - role: assistant
        content: |-
          Quicksort is a divide-and-conquer sorting algorithm:

          1. Choose a pivot element from the array
          2. Partition: rearrange elements so smaller values are on the left, larger on the right
          3. Recursively apply quicksort to the left and right partitions

          Time Complexity:
          - Best/Average: O(n log n)
          - Worst case: O(n²) when poorly chosen pivots

    # Inline rubrics - simple string format
    rubrics:
      - Mentions divide-and-conquer approach
      - Explains the partition step
      - States time complexity correctly

  # ==========================================
  # Example 2: Detailed rubric objects
  # Demonstrates: rubric objects with weights and required flags
  # ==========================================
  - id: technical-writing-detailed

    expected_outcome: |-
      Write a comprehensive guide on HTTP status codes with examples

    input_messages:
      - role: user
        content: Write a guide explaining HTTP status codes

    expected_messages:
      - role: assistant
        content: |-
          # HTTP Status Codes Guide

          ## 2xx Success
          - 200 OK: Request succeeded
          - 201 Created: Resource created successfully

          ## 4xx Client Errors
          - 400 Bad Request: Invalid syntax
          - 404 Not Found: Resource doesn't exist

          ## 5xx Server Errors
          - 500 Internal Server Error: Server-side error

    # Detailed rubric objects with weights and required flags
    rubrics:
      - id: structure
        expected_outcome: Has clear headings and organization
        weight: 1.0
        required: true

      - id: success-codes
        expected_outcome: Covers 2xx success codes with examples
        weight: 2.0
        required: true

      - id: client-errors
        expected_outcome: Explains 4xx client error codes
        weight: 2.0
        required: true

      - id: server-errors
        expected_outcome: Explains 5xx server error codes
        weight: 1.5
        required: false

      - id: practical-examples
        expected_outcome: Includes practical use case examples
        weight: 1.0
        required: false

  # ==========================================
  # Example 3: Multiple evaluators with rubric
  # Demonstrates: combining rubric evaluator with other evaluators
  # ==========================================
  - id: code-quality-multi-eval
    # Baseline note: candidates without type hints/edge handling often score lower (~0.75).

    expected_outcome: |-
      Python function that validates email addresses with proper error handling

    input_messages:
      - role: user
        content: Write a Python function to validate email addresses

    expected_messages:
      - role: assistant
        content: |-
          import re
          from typing import Optional

          def validate_email(email: str) -> bool:
              """
              Validates if a string is a properly formatted email address.
              
              Args:
                  email: The email string to validate
                  
              Returns:
                  True if valid email format, False otherwise
              """
              if not email or not isinstance(email, str):
                  return False
              
              pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
              return bool(re.match(pattern, email))

    # Inline rubrics for semantic checks
    rubrics:
      - Uses regular expressions for email validation
      - Includes type hints
      - Has docstring documentation
      - Handles edge cases (None, empty string)

    execution:
      evaluators:
        # Rubric evaluator is auto-added from inline rubrics field

        # Additional code evaluator for syntax checking
        - name: python_syntax
          type: code_judge
          script: ["uv", "run", "python", "check_syntax.py"]

  # ==========================================
  # Example 4: Using expected_outcome without rubrics
  # Demonstrates: expected_outcome as an alias for outcome
  # Note: Use 'agentv generate rubrics' to create rubrics from expected_outcome
  # ==========================================
  - id: summary-task

    # expected_outcome is the new preferred field name (outcome still works for backward compatibility)
    expected_outcome: |-
      Provide a concise summary of the key points in under 50 words

    input_messages:
      - role: user
        content: |-
          Summarize this article:

          Climate change is accelerating faster than predicted. Recent studies show
          Arctic ice melting at unprecedented rates, sea levels rising, and extreme
          weather events becoming more frequent. Scientists urge immediate action to
          reduce carbon emissions and transition to renewable energy sources.

    expected_messages:
      - role: assistant
        content: |-
          Climate change accelerates with rapid Arctic ice loss and rising seas.
          Extreme weather increases. Scientists call for urgent carbon emission
          cuts and renewable energy adoption.

    # No rubrics defined - will use default llm_judge evaluator
    # To generate rubrics: agentv generate rubrics evals/rubric-examples.yaml

  # ==========================================
  # Example 5: Score-range rubrics (PROPOSED)
  # Demonstrates: proposed per-criterion 0–10 score_ranges with required_min_score gating
  # Status: This example matches the OpenSpec change proposal `add-rubric-score-ranges`.
  #         It is NOT supported by the current runtime until that change is implemented.
  # ==========================================
  - id: correctness-score-range-proposed

    expected_outcome: |-
      Answer the question correctly and completely.

    input_messages:
      - role: user
        content: What is 15 + 27?

    expected_messages:
      - role: assistant
        content: 42

    # Proposed rubric criterion with score_ranges.
    # The judge assigns an integer score 0..10 for each criterion id.
    # AgentV normalizes each criterion score to 0..1 and aggregates deterministically.
    rubrics:
      - id: correctness
        weight: 1.0
        required_min_score: 10
        score_ranges:
          - score_range: [0, 2]
            expected_outcome: Incorrect or nonsensical answer.
          - score_range: [3, 6]
            expected_outcome: Partially correct but has clear errors or missing reasoning.
          - score_range: [7, 9]
            expected_outcome: Correct answer with minor issues (e.g., unclear explanation).
          - score_range: [10, 10]
            expected_outcome: Fully correct and clear.

  # ==========================================
  # Example 6: Multi-criteria score_ranges (PROPOSED)
  # Demonstrates: multiple rubric ids, each with 0–10 score_ranges, then weighted aggregation.
  # Real-world intent: grading a summary on both factual accuracy and brevity.
  # Status: Proposed only; not supported until `add-rubric-score-ranges` is implemented.
  # ==========================================
  - id: summary-multi-criteria-score-ranges-proposed

    expected_outcome: |-
      Provide an accurate summary in under 50 words.

    input_messages:
      - role: user
        content: |-
          Summarize this article in under 50 words:

          Climate change is accelerating faster than predicted. Recent studies show
          Arctic ice melting at unprecedented rates, sea levels rising, and extreme
          weather events becoming more frequent. Scientists urge immediate action to
          reduce carbon emissions and transition to renewable energy sources.

    expected_messages:
      - role: assistant
        content: |-
          Climate change is accelerating with rapid Arctic ice loss, rising seas, and
          more extreme weather. Scientists urge urgent emissions cuts and a transition
          to renewable energy.

    rubrics:
      - id: factual_accuracy
        weight: 2.0
        required_min_score: 8
        score_ranges:
          - score_range: [0, 2]
            expected_outcome: Contains major factual errors or contradicts the article.
          - score_range: [3, 5]
            expected_outcome: Mostly on-topic but includes at least one clear factual error or misstates a key claim.
          - score_range: [6, 7]
            expected_outcome: Generally accurate but misses an important point or slightly distorts emphasis.
          - score_range: [8, 9]
            expected_outcome: Accurate and covers the key points with only minor omissions.
          - score_range: [10, 10]
            expected_outcome: Fully accurate, captures all key points with no distortions.

      - id: brevity_and_clarity
        weight: 1.0
        score_ranges:
          - score_range: [0, 2]
            expected_outcome: Exceeds 50 words or is hard to understand.
          - score_range: [3, 5]
            expected_outcome: Under 50 words but unclear, repetitive, or poorly structured.
          - score_range: [6, 7]
            expected_outcome: Under 50 words and mostly clear, but could be more concise or better phrased.
          - score_range: [8, 9]
            expected_outcome: Under 50 words, clear and concise.
          - score_range: [10, 10]
            expected_outcome: Under 50 words, exceptionally clear, concise, and well phrased.
