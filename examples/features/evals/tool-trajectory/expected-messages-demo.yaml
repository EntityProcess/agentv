# AgentV Expected Tool Calls Demo
# Demonstrates the expected_tool_calls evaluator for validating tool_calls against traces
#
# The expected_tool_calls evaluator extracts tool_calls from assistant messages in
# expected_messages and validates them sequentially against the actual trace.
#
# This is an alternative pattern to tool_trajectory for when you want to specify
# expected tool calls inline with the conversation flow.
#
# Setup:
#   1. Create examples/features/.env with:
#      TOOL_TRAJECTORY_DIR=/absolute/path/to/examples/features/evals/tool-trajectory
#   2. Run: cd examples/features && npx agentv eval evals/tool-trajectory/expected-messages-demo.yaml --target mock_agent

$schema: agentv-eval-v2
description: Expected tool_calls validation examples

# Use mock_agent CLI target that returns trace data
target: mock_agent

evalcases:
  # ==========================================
  # Example 1: Basic tool_calls validation
  # Use case: Validate specific tools were called in order
  # The mock agent triggers "research" scenario with knowledgeSearch and documentRetrieve
  # Expected score: 1.0 (all tool_calls match)
  # ==========================================
  - id: basic-tool-calls-match
    expected_outcome: |-
      Agent searches the knowledge base and retrieves documents.

    input_messages:
      - role: user
        content: Research the key differences between REST and GraphQL APIs.

    # Specify expected tool_calls in expected_messages
    expected_messages:
      - role: assistant
        content: I'll research this topic for you.
        tool_calls:
          - tool: knowledgeSearch
          - tool: knowledgeSearch
          - tool: documentRetrieve

    execution:
      evaluators:
        - name: tool-calls-validator
          type: expected_tool_calls

  # ==========================================
  # Example 2: Validate with input matching
  # Use case: Ensure specific inputs are passed to tools
  # The mock agent triggers "metrics" scenario
  # Expected score: 1.0 if inputs match exactly
  # ==========================================
  - id: tool-calls-with-input
    expected_outcome: |-
      Agent retrieves CPU and memory metrics for the production server.

    input_messages:
      - role: user
        content: What are the current system metrics for CPU and memory?

    expected_messages:
      - role: assistant
        content: I'll check the system metrics.
        tool_calls:
          - tool: getCpuMetrics
            input:
              server: prod-1
          - tool: getMemoryMetrics
            input:
              server: prod-1

    execution:
      evaluators:
        - name: metrics-input-validator
          type: expected_tool_calls

  # ==========================================
  # Example 3: Data pipeline workflow
  # Use case: Validate multi-step data processing workflow
  # The mock agent triggers "data pipeline" scenario
  # Expected score: 1.0 (all 4 tools match in order)
  # ==========================================
  - id: pipeline-tool-calls
    expected_outcome: |-
      Agent follows the complete data processing pipeline.

    input_messages:
      - role: user
        content: Process the customer data from the API endpoint.

    expected_messages:
      - role: assistant
        content: I'll process the data through the pipeline.
        tool_calls:
          - tool: fetchData
          - tool: validateSchema
          - tool: transformData
          - tool: saveResults

    execution:
      evaluators:
        - name: pipeline-validator
          type: expected_tool_calls

  # ==========================================
  # Example 4: Authentication flow
  # Use case: Validate security-critical tool sequence
  # The mock agent triggers "auth" scenario
  # Expected score: 1.0 (exact sequence match)
  # ==========================================
  - id: auth-tool-calls
    expected_outcome: |-
      Agent performs authentication steps in correct order.

    input_messages:
      - role: user
        content: Authenticate the user with provided credentials.

    expected_messages:
      - role: assistant
        content: Authenticating user...
        tool_calls:
          - tool: checkCredentials
          - tool: generateToken
          - tool: auditLog

    execution:
      evaluators:
        - name: auth-validator
          type: expected_tool_calls

  # ==========================================
  # Example 5: Partial match - wrong tool
  # Use case: Demonstrate scoring when tool names don't match
  # The mock agent triggers "research" scenario but we expect different tools
  # Expected score: ~0.33 (1 of 3 matches - documentRetrieve present but position differs)
  # ==========================================
  - id: partial-match-wrong-tool
    expected_outcome: |-
      Agent uses different tools than expected.

    input_messages:
      - role: user
        content: Research the topic quickly.

    expected_messages:
      - role: assistant
        content: Researching...
        tool_calls:
          - tool: quickSearch        # Will get knowledgeSearch instead
          - tool: knowledgeSearch    # Will get knowledgeSearch (matches!)
          - tool: summarize          # Will get documentRetrieve instead

    execution:
      evaluators:
        - name: partial-validator
          type: expected_tool_calls

  # ==========================================
  # Example 6: Branch Deactivation (Precise)
  # Use case: Validate exact tool calls with inputs (Pattern A from openspec)
  # The mock agent triggers "branch deactivation" scenario
  # Expected score: 1.0 (exact sequence and input match)
  # ==========================================
  - id: branch-deactivation-precise
    expected_outcome: |-
      Agent researches branch deactivation process, permissions, and prerequisites.

    input_messages:
      - role: user
        content: How do I deactivate a branch?

    expected_messages:
      - role: assistant
        content: To deactivate a branch...
        tool_calls:
          - tool: semanticSearch
            input: { query: "branch deactivation process" }
          - tool: semanticSearch
            input: { query: "branch permissions requirements" }
          - tool: semanticSearch
            input: { query: "branch deactivation prerequisites" }

    execution:
      evaluators:
        - name: branch-validator
          type: expected_tool_calls

  # ==========================================
  # Example 7: Branch Deactivation (Combined)
  # Use case: Combine expected_messages with tool_trajectory for robust validation
  # The mock agent triggers "branch deactivation" scenario
  # Expected score: 1.0 (both evaluators pass)
  # ==========================================
  - id: branch-deactivation-combined
    expected_outcome: |-
      Agent researches branch deactivation with correct inputs and sufficient depth.

    input_messages:
      - role: user
        content: How do I deactivate a branch?

    # Precise validation of expected flow and inputs
    expected_messages:
      - role: assistant
        content: To deactivate a branch...
        tool_calls:
          - tool: semanticSearch
            input: { query: "branch deactivation process" }
          - tool: semanticSearch
            input: { query: "branch permissions requirements" }
          - tool: semanticSearch
            input: { query: "branch deactivation prerequisites" }

    execution:
      evaluators:
        # Validate exact sequence and inputs
        - name: sequence-validator
          type: expected_tool_calls
        
        # Safety net: must have at least 3 searches (redundant here but shows combination)
        - name: depth-validator
          type: tool_trajectory
          mode: any_order
          minimums:
            semanticSearch: 3
