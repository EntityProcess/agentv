# Execution Metrics Evaluator Demo
# Demonstrates the built-in execution_metrics evaluator for declarative threshold-based checks.
#
# The execution_metrics evaluator allows you to set limits on:
# - max_tool_calls: Maximum number of tool invocations
# - max_llm_calls: Maximum number of LLM calls (assistant messages)
# - max_tokens: Maximum total tokens (input + output)
# - max_cost_usd: Maximum cost in USD
# - max_duration_ms: Maximum execution duration in milliseconds
# - target_exploration_ratio: Target ratio of read-only tool calls (with tolerance)
#
# Only specified thresholds are checked; omitted ones are ignored.
# Score is proportional: hits / (hits + misses)
#
# Run with:
#   bun agentv eval examples/features/execution-metrics/evals/dataset.yaml --dry-run

description: Demonstrates the built-in execution_metrics evaluator

# Mock agent that returns realistic execution metrics
execution:
  target: mock_metrics_agent

cases:
  # ==========================================
  # Example 1: Simple threshold check - PASS
  # Check that an efficient agent stays within limits
  # ==========================================
  - id: simple-thresholds-pass

    criteria: |-
      Agent responds efficiently within all specified limits.

    input:
      - role: user
        content: Hello, this is a simple question.

    execution:
      evaluators:
        - name: efficiency-check
          type: execution_metrics
          max_tool_calls: 10
          max_tokens: 2000
          max_duration_ms: 10000

  # ==========================================
  # Example 2: Multiple thresholds - PASS
  # Comprehensive check with all threshold types
  # ==========================================
  - id: comprehensive-thresholds

    criteria: |-
      Agent performs a task within all efficiency constraints.

    input:
      - role: user
        content: Hello, give me a simple response.

    execution:
      evaluators:
        - name: full-efficiency-check
          type: execution_metrics
          max_tool_calls: 15
          max_llm_calls: 5
          max_tokens: 3000
          max_cost_usd: 0.1
          max_duration_ms: 30000

  # ==========================================
  # Example 3: Research task with tool trajectory + metrics
  # Combines multiple evaluator types
  # ==========================================
  - id: research-with-metrics

    criteria: |-
      Agent performs research and uses tools efficiently.
      Metrics reflect reasonable token usage and tool calls.

    input:
      - role: user
        content: Research and analyze the topic of machine learning.

    execution:
      evaluators:
        # Check tool trajectory
        - name: trajectory-check
          type: tool_trajectory
          mode: any_order
          minimums:
            search: 1

        # Check execution efficiency
        - name: metrics-check
          type: execution_metrics
          max_tool_calls: 20
          max_tokens: 5000

  # ==========================================
  # Example 4: Exploration ratio check
  # Validates the balance between read-only and write operations
  # ==========================================
  - id: exploration-ratio-check

    criteria: |-
      Agent maintains a good balance of exploration (reading) vs
      action (writing/editing) tool calls.

    input:
      - role: user
        content: Read the documentation and make small improvements.

    execution:
      evaluators:
        - name: exploration-balance
          type: execution_metrics
          target_exploration_ratio: 0.6  # 60% should be read-only tools
          exploration_tolerance: 0.2      # Allow +/- 20% variance

  # ==========================================
  # Example 5: Strict cost budget
  # Useful for cost-sensitive applications
  # ==========================================
  - id: cost-budget-check

    criteria: |-
      Agent completes the task within the specified cost budget.

    input:
      - role: user
        content: Generate a brief summary.

    execution:
      evaluators:
        - name: cost-check
          type: execution_metrics
          max_cost_usd: 0.05
          weight: 2.0  # Double weight for cost compliance

  # ==========================================
  # Example 6: Combining with code_judge
  # Use execution_metrics for thresholds, code_judge for custom logic
  # ==========================================
  - id: hybrid-evaluation

    criteria: |-
      Agent passes both declarative thresholds and custom evaluation.

    input:
      - role: user
        content: Process the data efficiently.

    execution:
      evaluators:
        # Declarative threshold checks
        - name: metric-thresholds
          type: execution_metrics
          max_tool_calls: 10
          max_duration_ms: 5000

        # Custom evaluation logic (for more complex checks)
        - name: custom-check
          type: code_judge
          script: ["bun", "run", "../scripts/check-metrics-present.ts"]
