# Design: ACE Optimizer Integration

## Architecture

The optimization feature will be implemented as a new module in `@agentv/core` and exposed via the CLI.

### 1. Configuration Schema
We will introduce a new configuration type for Optimizers.
File extension: `.yaml` (e.g., `optimizers/ace-code-generation.yaml`).

```yaml
description: string
type: "ace"
eval_files: string[] # Paths to eval files
playbook_path: string # Path to save/load the playbook
max_epochs: number # Number of optimization iterations
allow_dynamic_sections: boolean # Allow ACE to create new playbook sections
```

**Metric Scoring**: The initial version supports a single numeric metric in the 0-1 range. This can be a simple pass/fail (0 or 1) or a weighted composite score (e.g., 0.5 for correct output + 0.15 for good reasoning). The metric is computed by evaluating the optimized prompt against the test cases in `eval_files`.

**Playbook Structure**: Playbooks are lightweight JSON files following the Ax ACE specification:
```json
{
  "version": 1,
  "sections": {
    "Core Principles": [
      {
        "id": "core-prin-a3f2b891",
        "section": "Core Principles",
        "content": "Always validate input types",
        "helpfulCount": 0,
        "harmfulCount": 0,
        "createdAt": "2025-01-15T10:30:00.000Z",
        "updatedAt": "2025-01-15T10:30:00.000Z",
        "tags": ["validation"]
      }
    ],
    "Edge Cases": [
      {
        "id": "edge-cas-7d4e1c92",
        "section": "Edge Cases",
        "content": "Handle null/undefined gracefully",
        "helpfulCount": 2,
        "harmfulCount": 0,
        "createdAt": "2025-01-15T10:32:00.000Z",
        "updatedAt": "2025-01-15T11:45:00.000Z"
      }
    ]
  },
  "stats": {
    "bulletCount": 2,
    "helpfulCount": 2,
    "harmfulCount": 0,
    "tokenEstimate": 45
  },
  "updatedAt": "2025-01-15T11:45:00.000Z",
  "description": "Learned optimization insights"
}
```

Bullet IDs are auto-generated by Ax in the format `{section-prefix}-{randomHex}` (e.g., `core-prin-a3f2b891`). The playbook tracks feedback counters (`helpfulCount`, `harmfulCount`) used for pruning low-value bullets when sections grow too large.

### 2. Core Implementation (`packages/core`)

**New Module: `optimization`**
- `OptimizerConfig`: Zod schema for the configuration.
- `Optimizer`: Interface for optimization strategies.
- `AceOptimizer`: Implementation using `@ax-llm/ax`.

**Integration with Evaluation**
- The `AceOptimizer` needs to run evaluations to measure performance.
- We will reuse the existing `EvaluationEngine` (or equivalent) to run the test cases defined in `eval_files`.
- The optimizer will iterate:
    1.  Ax generates a candidate (or updates the playbook).
    2.  AgentV runs the evals using the candidate.
    3.  AgentV computes a single numeric score (0-1 range) per eval case. This can be a simple binary score or a weighted composite.
    4.  Ax uses the scores to improve the playbook via reflection and curation.

**Generator Output Requirements**
- ACE's Reflector requires access to the generator's reasoning trace to analyze which playbook bullets helped or hurt.
- AgentV must capture a `thought` or `reasoning` field from the generator output (if present).
- Implementation approach:
  - Extend `EvaluationResult` type to include optional `reasoning?: string` field (already exists in current schema).
  - Extract reasoning from the candidate answer if it contains a structured `thought` field.
  - Pass this reasoning to ACE as `generator_reasoning` input for the Reflector.
- For eval cases where the LLM naturally outputs reasoning (e.g., Chain-of-Thought prompts), this will be captured automatically.
- For cases without explicit reasoning output, the Reflector will work with just the answer and feedback signals.

### 3. CLI Implementation (`apps/cli`)

**New Command: `optimize`**
- Usage: `agentv optimize <config-file>`
- Responsibilities:
    - Load and validate the optimizer config.
    - Resolve paths (eval files, playbook).
    - Instantiate the optimizer.
    - Run the optimization loop.
    - Report progress to the console.

### 4. Ax Integration
- We will add `@ax-llm/ax` as a dependency to `@agentv/core`.
- We will map AgentV's `EvalResult` to the feedback format expected by Ax's ACE.

## Data Flow

1.  **User** runs `agentv optimize my-config.yaml`.
2.  **CLI** reads `my-config.yaml`.
3.  **CLI** initializes `AceOptimizer` with the config.
4.  **AceOptimizer** loads the `playbook` (if exists).
5.  **AceOptimizer** starts the optimization loop.
6.  **AceOptimizer** requests evaluation of the current state.
7.  **EvaluationRunner** (from core) runs the specified `eval_files`.
8.  **EvaluationRunner** returns metrics (e.g., correctness score).
9.  **AceOptimizer** updates the `playbook` based on metrics and reflection.
10. **AceOptimizer** saves the `playbook` to disk.
